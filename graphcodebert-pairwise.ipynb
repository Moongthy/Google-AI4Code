{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2138d32a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-01T03:40:42.362466Z",
     "iopub.status.busy": "2022-08-01T03:40:42.361997Z",
     "iopub.status.idle": "2022-08-01T03:40:42.387353Z",
     "shell.execute_reply": "2022-08-01T03:40:42.386506Z"
    },
    "papermill": {
     "duration": 0.03579,
     "end_time": "2022-08-01T03:40:42.389653",
     "exception": false,
     "start_time": "2022-08-01T03:40:42.353863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.data_dir = Path('/kaggle/input/AI4Code')\n",
    "    \n",
    "    def read_notebook(self, path):\n",
    "        return (\n",
    "            pd.read_json(path, dtype={'cell_type': 'category', 'source': 'str'})\n",
    "                .assign(id=path.stem)\n",
    "                .rename_axis('cell_id')\n",
    "            )\n",
    "    \n",
    "    def get_notebooks_test(self):\n",
    "        paths_train = list((self.data_dir / 'test').glob('*.json'))\n",
    "        notebooks_test = [\n",
    "            self.read_notebook(path) for path in tqdm(paths_train, desc='Test NBs')\n",
    "        ]\n",
    "        return notebooks_test\n",
    "    \n",
    "    def get_test_df(self):\n",
    "        notebooks_test = self.get_notebooks_test()\n",
    "        df = (\n",
    "            pd.concat(notebooks_test)\n",
    "                .set_index('id', append=True)\n",
    "                .swaplevel()\n",
    "                .sort_index(level='id', sort_remaining=False)\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "    def clean_code(self, cell):\n",
    "        return str(cell).replace('\\\\n', '\\n')\n",
    "    \n",
    "    def sample_cells(self, cells, n=20):\n",
    "        cells = [self.clean_code(cell) for cell in cells]\n",
    "\n",
    "        if n >= len(cells): # 코드 셀이 20개 이하라면 그냥 반환\n",
    "            return [cell[:200] for cell in cells]\n",
    "        else:\n",
    "            results = []\n",
    "            step = len(cells) / n # 총 20개의 코드셀이 샘플링 되도록 스텝을 조절\n",
    "            idx = 0\n",
    "            while int(np.round(idx) < len(cells)):\n",
    "                results.append(cells[int(np.round(idx))])\n",
    "                idx += step\n",
    "            assert cells[0] in results # 첫번쨰 코드셀은 반드시 들어가야 한다?\n",
    "            if cells[-1] not in results: # 말전 코드셀은 반드시 들어가야 한다?\n",
    "                results[-1] = cells[-1]\n",
    "            return results\n",
    "        \n",
    "    def get_features(self, df):\n",
    "        features = dict()\n",
    "        df = df.sort_values('rank').reset_index(drop=True)\n",
    "\n",
    "        for idx, sub_df in tqdm(df.groupby('id')):\n",
    "            features[idx] = dict()\n",
    "            total_md = sub_df[sub_df.cell_type == 'markdown'].shape[0]\n",
    "            code_sub_df = sub_df[sub_df.cell_type == 'code']\n",
    "            total_code = code_sub_df.shape[0]\n",
    "            codes = self.sample_cells(code_sub_df.source.values, 20)\n",
    "            features[idx]['total_code'] = total_code\n",
    "            features[idx]['total_md'] = total_md\n",
    "            features[idx]['codes'] = codes\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b984873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:40:42.402585Z",
     "iopub.status.busy": "2022-08-01T03:40:42.401789Z",
     "iopub.status.idle": "2022-08-01T03:40:42.501767Z",
     "shell.execute_reply": "2022-08-01T03:40:42.500197Z"
    },
    "papermill": {
     "duration": 0.108241,
     "end_time": "2022-08-01T03:40:42.503836",
     "exception": false,
     "start_time": "2022-08-01T03:40:42.395595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 89.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 704.13it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor()\n",
    "\n",
    "test_df = preprocessor.get_test_df().reset_index()\n",
    "test_df['rank'] = test_df.groupby(['id', 'cell_type']).cumcount()\n",
    "test_df['pred'] = test_df.groupby(['id', 'cell_type'])['rank'].rank(pct=True)\n",
    "\n",
    "test_fts = preprocessor.get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90308e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:40:42.516979Z",
     "iopub.status.busy": "2022-08-01T03:40:42.516694Z",
     "iopub.status.idle": "2022-08-01T03:40:44.749712Z",
     "shell.execute_reply": "2022-08-01T03:40:44.748785Z"
    },
    "papermill": {
     "duration": 2.242476,
     "end_time": "2022-08-01T03:40:44.752249",
     "exception": false,
     "start_time": "2022-08-01T03:40:42.509773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import sys\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.top = nn.Linear(769, 1)\n",
    "\n",
    "    def forward(self, ids, mask, fts):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        x = torch.cat((x[:, 0, :], fts), 1)\n",
    "        x = self.top(x)\n",
    "        return x\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "    def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len\n",
    "        self.fts = fts\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[row.id]['codes']],\n",
    "            add_special_tokens=True,\n",
    "            max_length=23,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        n_md = self.fts[row.id]['total_md']\n",
    "        n_code = self.fts[row.id]['total_code']\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == len(mask)\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]            \n",
    "\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def predict(model_path, ckpt_path):\n",
    "    model = MarkdownModel(model_path)\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(ckpt_path))\n",
    "    BS = 32\n",
    "    NW = 2\n",
    "    MAX_LEN = 64\n",
    "    test_df['pct_rank'] = 0\n",
    "    test_ds = MarkdownDataset(test_df[test_df['cell_type'] == 'markdown'].reset_index(drop=True),\n",
    "                              md_max_len=64,\n",
    "                              total_max_len=512,\n",
    "                              model_name_or_path=model_path,\n",
    "                              fts=test_fts)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                             pin_memory=False, drop_last=False)\n",
    "    _, y_test = validate(model, test_loader)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684a564a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:40:44.765619Z",
     "iopub.status.busy": "2022-08-01T03:40:44.765171Z",
     "iopub.status.idle": "2022-08-01T03:41:07.688902Z",
     "shell.execute_reply": "2022-08-01T03:41:07.687248Z"
    },
    "papermill": {
     "duration": 22.933331,
     "end_time": "2022-08-01T03:41:07.691677",
     "exception": false,
     "start_time": "2022-08-01T03:40:44.758346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/huggingface-code-models/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /kaggle/input/huggingface-code-models/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/kaggle/input/huggingface-code-models/graphcodebert-base\"\n",
    "ckpt_path = \"/kaggle/input/codebert2/model_epoch_5_0.8499189849500974.bin\"\n",
    "y_test = predict(model_path, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73bf4c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:07.707846Z",
     "iopub.status.busy": "2022-08-01T03:41:07.706349Z",
     "iopub.status.idle": "2022-08-01T03:41:07.730166Z",
     "shell.execute_reply": "2022-08-01T03:41:07.729193Z"
    },
    "papermill": {
     "duration": 0.033409,
     "end_time": "2022-08-01T03:41:07.732162",
     "exception": false,
     "start_time": "2022-08-01T03:41:07.698753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 d22526d1 eb293dfc 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                         cell_order\n",
       "0  0009d135ece78d  0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e...\n",
       "1  0010483c12ba9b  7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4...\n",
       "2  0010a919d60e4f  23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b...\n",
       "3  0028856e09c5b7                012c9d02 d22526d1 eb293dfc 3ae7ece3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\n",
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d9ea9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:07.746800Z",
     "iopub.status.busy": "2022-08-01T03:41:07.746009Z",
     "iopub.status.idle": "2022-08-01T03:41:07.753391Z",
     "shell.execute_reply": "2022-08-01T03:41:07.752533Z"
    },
    "papermill": {
     "duration": 0.016957,
     "end_time": "2022-08-01T03:41:07.755567",
     "exception": false,
     "start_time": "2022-08-01T03:41:07.738610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee08ae",
   "metadata": {
    "papermill": {
     "duration": 0.006156,
     "end_time": "2022-08-01T03:41:07.768206",
     "exception": false,
     "start_time": "2022-08-01T03:41:07.762050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pairwise: submission2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7062bd5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:07.782541Z",
     "iopub.status.busy": "2022-08-01T03:41:07.782276Z",
     "iopub.status.idle": "2022-08-01T03:41:29.210178Z",
     "shell.execute_reply": "2022-08-01T03:41:29.208778Z"
    },
    "papermill": {
     "duration": 21.438024,
     "end_time": "2022-08-01T03:41:29.212592",
     "exception": false,
     "start_time": "2022-08-01T03:41:07.774568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "PRETRAINED_MODEL_PATH = '/kaggle/input/pairwisemodels/checkpoint-18000'\n",
    "FINETUNED_MODEL_PATH = '/kaggle/input/pairwisemodels//my_own_model.bin'\n",
    "TOKENIZER_PATH = '/kaggle/input/pairwisemodels//my_own_tokenizer'\n",
    "\n",
    "data_dir = Path('/kaggle/input/AI4Code')\n",
    "\n",
    "def generate_triplet(df, mode='train'):\n",
    "  triplets = []\n",
    "  ids = df.id.unique()\n",
    "  random_drop = np.random.random(size=10000)>0.9\n",
    "  count = 0\n",
    "\n",
    "  for id, df_tmp in tqdm(df.groupby('id')):\n",
    "    df_tmp_markdown = df_tmp[df_tmp['cell_type']=='markdown']\n",
    "\n",
    "    df_tmp_code = df_tmp[df_tmp['cell_type']=='code']\n",
    "    df_tmp_code_rank = df_tmp_code['rank'].values\n",
    "    df_tmp_code_cell_id = df_tmp_code['cell_id'].values\n",
    "\n",
    "    for cell_id, rank in df_tmp_markdown[['cell_id', 'rank']].values:\n",
    "      labels = np.array([(r==(rank+1)) for r in df_tmp_code_rank]).astype('int')\n",
    "\n",
    "      for cid, label in zip(df_tmp_code_cell_id, labels):\n",
    "        count += 1\n",
    "        if label==1:\n",
    "          triplets.append( [cell_id, cid, label] )\n",
    "          # triplets.append( [cid, cell_id, label] )\n",
    "        elif mode == 'test':\n",
    "          triplets.append( [cell_id, cid, label] )\n",
    "          # triplets.append( [cid, cell_id, label] )\n",
    "        elif random_drop[count%10000]:\n",
    "          triplets.append( [cell_id, cid, label] )\n",
    "          # triplets.append( [cid, cell_id, label] )\n",
    "    \n",
    "  return triplets\n",
    "\n",
    "def preprocess_text(document):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(document))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    #return document\n",
    "    \n",
    "    # Lemmatization\n",
    "    tokens = document.split()\n",
    "    tokens = [stemmer.lemmatize(word) for word in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 3]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.distill_bert = AutoModel.from_pretrained(PRETRAINED_MODEL_PATH)\n",
    "        self.top = nn.Linear(512, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        x = self.distill_bert(ids, mask)[0]\n",
    "        x = self.dropout(x)\n",
    "        x = self.top(x[:, 0, :])\n",
    "        x = torch.sigmoid(x) \n",
    "        return x\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, max_len, mode='train'):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, do_lower_case=True)\n",
    "        self.mode=mode\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df[index]\n",
    "\n",
    "        label = row[-1]\n",
    "\n",
    "        txt = dict_cellid_source[row[0]] + '[SEP]' + dict_cellid_source[row[1]]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            txt,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = torch.LongTensor(inputs['input_ids'])\n",
    "        mask = torch.LongTensor(inputs['attention_mask'])\n",
    "\n",
    "        return ids, mask, torch.FloatTensor([label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader, mode='train'):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = np.zeros(len(val_loader.dataset), dtype='float32')\n",
    "    labels = []\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(inputs[0], inputs[1]).detach().cpu().numpy().ravel()\n",
    "\n",
    "            preds[count:count+len(pred)] = pred\n",
    "            count += len(pred)\n",
    "            \n",
    "            if mode=='test':\n",
    "              labels.append(target.detach().cpu().numpy().ravel())\n",
    "    if mode=='test':\n",
    "      return preds\n",
    "    else:\n",
    "      return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a7107d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:29.228190Z",
     "iopub.status.busy": "2022-08-01T03:41:29.227161Z",
     "iopub.status.idle": "2022-08-01T03:41:31.741396Z",
     "shell.execute_reply": "2022-08-01T03:41:31.740436Z"
    },
    "papermill": {
     "duration": 2.524856,
     "end_time": "2022-08-01T03:41:31.744479",
     "exception": false,
     "start_time": "2022-08-01T03:41:29.219623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 169.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 388.96it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(999,\n",
       " (tensor([  101, 25169,  2951,  4094,  2951,  4162,   102, 12324, 16371,  8737,\n",
       "           2100,  7399, 11208, 12324, 25462,  2951,  6364, 12324, 13523, 24759,\n",
       "           4140, 29521,  1052, 22571, 10994,  2013, 15315, 19738,  6826, 22511,\n",
       "          12324,  2013, 15315, 19738,  6826, 17463,  3217,  9623,  7741, 12324,\n",
       "           4781,  9289,  2121,  2013, 15315, 19738,  6826, 17463,  3217,  9623,\n",
       "           7741, 12324,  4094,  2013, 15315, 19738,  6826, 17727, 10421, 12324,\n",
       "           3722,  5714, 18780,  2121, 12324, 16101, 18442,  5371, 18442,  3328,\n",
       "          10556, 24679,  7953,  5371, 18442,  5371, 18442,  6140,  4130,  3693,\n",
       "          16101, 18442,  5371, 18442,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0.])))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS = 128\n",
    "NW = 8\n",
    "MAX_LEN = 128\n",
    "\n",
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()\n",
    "\n",
    "test_df.source = test_df.source.apply(preprocess_text)\n",
    "dict_cellid_source = dict(zip(test_df['cell_id'].values, test_df['source'].values))\n",
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=False)\n",
    "test_triplets = generate_triplet(test_df, mode = 'test')\n",
    "test_df[\"pct_rank\"] = 0\n",
    "test_ds = MarkdownDataset(test_triplets, max_len=MAX_LEN)\n",
    "test_loader = DataLoader(test_ds, batch_size=BS * 4, shuffle=False, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=False)\n",
    "import gc \n",
    "gc.collect()\n",
    "len(test_ds), test_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3caac2f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:31.763881Z",
     "iopub.status.busy": "2022-08-01T03:41:31.763525Z",
     "iopub.status.idle": "2022-08-01T03:41:37.526229Z",
     "shell.execute_reply": "2022-08-01T03:41:37.524557Z"
    },
    "papermill": {
     "duration": 5.775329,
     "end_time": "2022-08-01T03:41:37.529149",
     "exception": false,
     "start_time": "2022-08-01T03:41:31.753820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/pairwisemodels/checkpoint-18000 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /kaggle/input/pairwisemodels/checkpoint-18000 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "model = MarkdownModel()\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(FINETUNED_MODEL_PATH))\n",
    "y_test = validate(model, test_loader, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec5caae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:37.547773Z",
     "iopub.status.busy": "2022-08-01T03:41:37.547454Z",
     "iopub.status.idle": "2022-08-01T03:41:37.777999Z",
     "shell.execute_reply": "2022-08-01T03:41:37.776915Z"
    },
    "papermill": {
     "duration": 0.244338,
     "end_time": "2022-08-01T03:41:37.782379",
     "exception": false,
     "start_time": "2022-08-01T03:41:37.538041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 448.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_copy = y_test\n",
    "pred_vals = []\n",
    "count = 0\n",
    "for id, df_tmp in tqdm(test_df.groupby('id')):\n",
    "    df_tmp_mark = df_tmp[df_tmp['cell_type']=='markdown']\n",
    "    df_tmp_code = df_tmp[df_tmp['cell_type']!='markdown']\n",
    "    df_tmp_code_rank = df_tmp_code['rank'].rank().values\n",
    "    N_code = len(df_tmp_code_rank)\n",
    "    N_mark = len(df_tmp_mark)\n",
    "    \n",
    "    preds_tmp = preds_copy[count:count+N_mark * N_code]\n",
    "    \n",
    "    count += N_mark * N_code\n",
    "    \n",
    "    for i in range(N_mark):\n",
    "      pred = preds_tmp[i*N_code:i*N_code+N_code] \n",
    "    \n",
    "      softmax = np.exp((pred-np.mean(pred)) *20)/np.sum(np.exp((pred-np.mean(pred)) *20)) \n",
    "    \n",
    "      rank = np.sum(softmax * df_tmp_code_rank)\n",
    "      pred_vals.append(rank)\n",
    "    \n",
    "del model\n",
    "del test_triplets[:]\n",
    "del dict_cellid_source\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15831661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:37.811408Z",
     "iopub.status.busy": "2022-08-01T03:41:37.810729Z",
     "iopub.status.idle": "2022-08-01T03:41:37.838330Z",
     "shell.execute_reply": "2022-08-01T03:41:37.835849Z"
    },
    "papermill": {
     "duration": 0.045111,
     "end_time": "2022-08-01T03:41:37.841269",
     "exception": false,
     "start_time": "2022-08-01T03:41:37.796158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c 0a226b6a 8cb8d28a c6cd22db 1372ae9b 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>54c7cab3 7f270e34 fe66203e 7844d5f8 5ce8863c 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>aafc3d23 b7578789 23607d04 4ae17669 bbff12d4 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 d22526d1 eb293dfc 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                         cell_order\n",
       "0  0009d135ece78d  ddfd239c 0a226b6a 8cb8d28a c6cd22db 1372ae9b 9...\n",
       "1  0010483c12ba9b  54c7cab3 7f270e34 fe66203e 7844d5f8 5ce8863c 4...\n",
       "2  0010a919d60e4f  aafc3d23 b7578789 23607d04 4ae17669 bbff12d4 8...\n",
       "3  0028856e09c5b7                012c9d02 d22526d1 eb293dfc 3ae7ece3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = pred_vals\n",
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97fd912b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:37.873779Z",
     "iopub.status.busy": "2022-08-01T03:41:37.873438Z",
     "iopub.status.idle": "2022-08-01T03:41:37.884374Z",
     "shell.execute_reply": "2022-08-01T03:41:37.881736Z"
    },
    "papermill": {
     "duration": 0.034403,
     "end_time": "2022-08-01T03:41:37.893700",
     "exception": false,
     "start_time": "2022-08-01T03:41:37.859297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac3c1e",
   "metadata": {
    "papermill": {
     "duration": 0.012622,
     "end_time": "2022-08-01T03:41:37.923459",
     "exception": false,
     "start_time": "2022-08-01T03:41:37.910837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Rank Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe1fdd65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:37.949381Z",
     "iopub.status.busy": "2022-08-01T03:41:37.948987Z",
     "iopub.status.idle": "2022-08-01T03:41:37.968335Z",
     "shell.execute_reply": "2022-08-01T03:41:37.967125Z"
    },
    "papermill": {
     "duration": 0.036353,
     "end_time": "2022-08-01T03:41:37.970797",
     "exception": false,
     "start_time": "2022-08-01T03:41:37.934444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading the submissions\n",
    "df_1 = pd.read_csv('submission1.csv')\n",
    "df_2 = pd.read_csv('submission2.csv')\n",
    "\n",
    "# Averaging the indices and sorting the resulting submission by the aggregated ensembled indices\n",
    "new_samples = []\n",
    "for sample_idx in range(len(df_1)):\n",
    "    # {'0a226b6a': 0, ...}\n",
    "    sample_1 = {k: v for v, k in enumerate(df_1.iloc[sample_idx]['cell_order'].split(' '))}\n",
    "    sample_2 = {k: v for v, k in enumerate(df_2.iloc[sample_idx]['cell_order'].split(' '))}\n",
    "    for key in sample_1: \n",
    "        sample_1[key] = ((sample_1[key] * 0.748) + (sample_2[key] * 0.252))\n",
    "    new_samples.append(' '.join([i[0] for i in list(sorted(sample_1.items(), key = lambda x: x[1]))]))\n",
    "df_1['cell_order'] = new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f76fef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T03:41:37.997027Z",
     "iopub.status.busy": "2022-08-01T03:41:37.995958Z",
     "iopub.status.idle": "2022-08-01T03:41:38.011323Z",
     "shell.execute_reply": "2022-08-01T03:41:38.009466Z"
    },
    "papermill": {
     "duration": 0.031763,
     "end_time": "2022-08-01T03:41:38.014077",
     "exception": false,
     "start_time": "2022-08-01T03:41:37.982314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 d22526d1 eb293dfc 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                         cell_order\n",
       "0  0009d135ece78d  0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e...\n",
       "1  0010483c12ba9b  7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4...\n",
       "2  0010a919d60e4f  23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b...\n",
       "3  0028856e09c5b7                012c9d02 d22526d1 eb293dfc 3ae7ece3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.to_csv('submission.csv', index = False)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23035d",
   "metadata": {
    "papermill": {
     "duration": 0.012315,
     "end_time": "2022-08-01T03:41:38.039793",
     "exception": false,
     "start_time": "2022-08-01T03:41:38.027478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.159548,
   "end_time": "2022-08-01T03:41:39.575752",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-01T03:40:33.416204",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
